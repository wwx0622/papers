# title
[Latent graph learning with dual-channel attention for relation extraction](https://www.sciencedirect.com/science/article/pii/S0950705122007389)
# Abstract
作为信息检索的一个组成部分，关系抽取旨在预测文本中两个给定实体之间的关系类型。当遇到包含许多与任务无关的标记的长文本时，此任务将变得具有挑战性。最近解决这个问题的尝试已经求助于学习token之间的相关性。然而，如何获得合适的图来更好地表示相关性仍然是一个悬而未决的问题，而现有的方法还有改进的余地。在本文中，我们提出了一种新的潜在图学习方法，以增强感兴趣实体的上下文信息表达能力。特别是，我们设计了一种用于**多视图图学习的双通道注意机制**，并将所学习的多视图汇集在一起，以筛选潜在图的无关tokens。该过程可以重复多次以细化潜在结构。我们表明，与强基线模型和先前的多视图图学习方法相比，我们的方法在多个基准数据集上实现了优异的性能。
# Conclusion
- 提出了DA-GPN，这是一种用于以端到端方式加强关系提取的新型图形模型。我们的模型通过三个关键设计动态学习复杂的图结构，并在长序列中发现token之间的隐式关系：
  - 用于初始化图拓扑的初步图学习，
  - 用于细化潜在图的多视图图池，
  - 用于增强令牌之间关系学习的双通道自关注。

# Introduction
关系提取（RE）旨在识别文本中给定实体对之间的未知语义关系，是各种下游自然语言处理任务的基础，从知识图扩展、问答、事件检测到自然语言生成。
为了不仅对局部环境进行建模，而且对长期的依赖关系进行建模，注意力机制已被用于构建更具表达力和更复杂的模型，如BERT及其变体。通过利用BERT进行预训练，RE模型的性能得到了改善。然而，上下文学习的基本约束仍然存在，不相关的词经常被纳入到BERT网络的计算中。
通过基于消息传递的GNN，图建模使我们能够了解有关token之间间接交互（例如，高阶或多跳依赖性）的更多有效信息。通常，图中的每个节点表示给定文本中的token或实体。边可以是由外部解析器导出的语法关系，但这种方法会在依赖项解析中引入额外的错误。依赖树独立于特定任务，可能无法反映实体关系的语义，在依赖树上学习实体表示可能会导致错误的关系推断。或者，最近的研究转向直接从文本中学习潜在图，使得图节点以及它们之间的边都指示目标关系。当文本是长序列时，这种方式变得非常具有挑战性。
在感兴趣的实体周围有许多不相关的标记，并且涉及复杂的语法关系。因此，发现（通过学习）与目标实体对相关的图拓扑是非常重要的。
关键是识别重要节点/边缘并过滤掉那些不重要的节点/边缘，这类似于卷积神经网络中的下采样（池 pooling）操作。根据多视图图学习，假设潜在token-token图中的边包含多种类型的关系，我们还考虑通过利用多视图图表示来学习潜在图。特别是考虑到图中常用的自我注意机制生成不足以捕获token之间有意义的交互，我们在多视图图生成中提出了一种称为**双通道自关注机制（Dual-channel self-Attention mechanism, DAttention）**的新方法，该方法从两个通道学习query和key，并自适应地将它们融合以进行评分。此外，我们还使用两阶段图细化技术从生成的图（即标记）中进一步提取较少相关的节点，以支持长文本重新预测。我们的框架还允许堆叠上述过程的多层，以对潜在图进行深度细化。在初始化图结构时，提出了一种不同的图初始化方法，以学习对应于多个视图的多个图，基于语言模型中预先训练的节点嵌入来捕获令牌之间的所有可能关系。然后，我们使用GCN来学习每个视图的相应节点表示。通过两阶段图细化，我们将初始潜在图反馈给潜在图学习模块的循环。
最后，将来自图学习模块和预训练语言模型的特征合并，以提供给预测层。实验证明了DA-GPN在令牌级潜在图学习方面的优势，并在长文本重任务的基准数据集上实现了新的技术状态。为了方便起见，我们将我们的框架称为DA-GPN。
本文的工作：
1. 提出了DA-GPN用于提取token级别的潜在图，改图学习模型生成多视图的图并传递潜在图的丰富信息，通过对多视图进过两阶段细化得到潜在图，对所有视图都重要的节点会被保留。
2. 提出了DAttention生成潜在图的多视图。
3. 我们还探讨了图形初始化的重要性以及在整个体系结构中提出的双通道注意。

[项目地址](https://github.com/dagservice/da-gpn)
# Method
![整体架构](image/DAttention%2001.png "整体架构")
三个重要组件：pre-trained language model, graph model, classification
- 预训练语言模型:$X \rightarrow H^0$，其中$X=\{x_1,...,xn\}, H^0=\{h_1, ... ,h_n\}$，这其中的$x_0和x_n$分别是开始和结束标记[CLS],[Sep]。编码后的结果送入后续处理。
- 图模型：本工作的核心部分，其目的是学习与目标实体对相关的潜在图。需要从不同的视图中寻找同时被列为重要的节点。
  1. 先学习多视图图（也即图集）。
  2. 聚合多视图图，得到潜在图。

  图模型包含三部分，初始化，潜在图学习和图细化。首先，利用图初始化技术生成多视图图，以捕获丰富的潜在token-token关系。然后进行多视图GCN以实现每个视图的节点嵌入，从而图池可以学习基于所有视图的综合决策的潜在图。此外，我们还提供了一种动态优化潜在图的方法，该方法重复了多视图图生成和图池的过程。
特别是，设计了一种双通道注意机制，以使用前一层中的学习节点表示生成多视图图。最后，我们将每个层中的潜在图表示聚合起来。
## Graph Initialization
基于$H^0$构造两个粗糙的视图，$H^0\in R^{d*n}$.考虑到token之间的关系可能是不对称的，我们将第k个视图图上节点对（i，j）之间的边定义为：
$A_{ij}^k = \frac{exp(ReLu(W_e*|Wsh^0_i-W_oh_j^0|))}{\sum_{j=1}^{n}exp(ReLu(W_e*|Wsh^0_i-W_oh_j^0|))}$，
其中$W_e\in R^{1*d}, W_s\in R^{d*d}, W_o\in R^{d*d}$。如此学习t次，得到$M^0 = \{A^1, A^2, .., A^t\}$。
## Graph learning
![图学习](image/DAttention%2002.png "图学习架构")
第一步：密集连接：$h_i^{l}=ReLu(\sum_{j=1}^n A_{ij}W^{l}g_j^l+b^l)$
$W^l\in R^{d_h*d_l}，d_h=d/l,d_l=d+d_h*(l-1)$
$b^l是偏置值$
$g^l_j=[h^0_j,;..;h^{l-1}_j]表示初始节点嵌入与先前的卷积层的级联$
**Graph pooling**:接下来，对于每个视图，我们执行图池以自适应地过滤出该视图中的重要节点。具体而言，我们利用面向节点的自关注机制开发了一种多视图图池方法，以筛选出与目标关系预测不太相关的噪声节点。我们首先获得$s_k\in R^{n*1}$中的节点自我注意分数，基于单个视图图的节点表示，如下所示：
$s_k=W_{pool}H_k^M+b_{pool}$
$H_k是第k个view的表示$
$I_{k}=\operatorname{top}-\operatorname{rank}\left(\mathbf{s}_{k},[r n]\right),其中0<r<=1$
然后通过选择所有视图都同意保留的节点来细化潜在图，即优化节点集：$i d x=I_{1} \cap I_{2} \cap \cdots \cap I_{t}$
因此，第i个导出的潜在图的拓扑由$A_{i d x, i d x}$描述, 其对应的图表示为$\hat{H}^{M_{i}}=H^{M_{i}} \odot A_{\text {mask }}$, 其中 $A_{\text {mask }}$是$A_{i d x, i d x}$的邻接矩阵，对于丢弃的节点为零。
**Compressing**：
为了在噪声数据中识别真正有用的标记，我们采用多视图投票的标记，获得一组高置信度的信息节点。具体而言，所有视图按以下方式聚合到潜在图G中：仅选择那些被所有视图识别为重要的视图，如图2所示。我们将此操作称为多视图压缩。因此，为了简单起见，我们省略了视图的索引。
在此阶段，潜在图G中的节点是这些节点在多个视图中的所有表示的串联，然后通过前馈层对每个节点表示进行特征变换，
$H^{G}=W_{\text {comp }}\left[\hat{H}_{1}^{M}, \ldots, \hat{H}_{t}^{M}\right]+b_{\text {comp }}$
其融合从每个视图学习的表示。
## Graph refining
![图细化](image/DAttention%2003.png "图细化")
**Dual-channel self-attention**：自我注意机制使人们能够更加关注重要信息，因此可以通过加权查询Q和密钥K之间的对齐度来充当过滤器。因此，获得适当的Q和K是很有价值的，这在现有研究中通常被忽略。在这里，我们设计了一个双通道自关注来优化查询和密钥的表达能力。具体来说，两个查询和密钥对分别通过两个通道学习，然后合成为一个新的查询-密钥对，计算如下:
$\left[\begin{array}{l}\hat{Q} \\ \hat{K}\end{array}\right]=\left(1-\left[\begin{array}{l}\lambda_{Q} \\ \lambda_{K}\end{array}\right]\right)\left[\begin{array}{l}W_{Q_{1}} Q_{1} \\ W_{K_{1}} K_{1}\end{array}\right]+\left[\begin{array}{l}\lambda_{Q} \\ \lambda_{K}\end{array}\right]\left[\begin{array}{l}W_{Q_{2}} Q_{2} \\ W_{K_{2}} K_{2}\end{array}\right]$
其中$Q_i=K_i=H^G$,
$W_{Q_i}和W_{K_i}是可训练权重矩阵$
$而\lambda_Q\lambda_K都是1*n的向量,通过以下途径学习$：
$\left[\begin{array}{c}\lambda_{Q} \\ \lambda_{K}\end{array}\right]=sigmoid\left(\left[\begin{array}{l}P_{Q_{1}} \\ P_{K_{1}}\end{array}\right]\left[\begin{array}{l}W_{Q_{1}} Q_{1} \\ W_{K_{1}} K_{1}\end{array}\right]+\left[\begin{array}{l}P_{Q_{2}} \\ P_{K_{2}}\end{array}\right]\left[\begin{array}{l}W_{Q_{2}} Q_{2} \\ W_{K_{2}} K_{2}\end{array}\right]\right)$
其中的P是可训练的1*d的矩阵
DAttention的评分函数如下：
$\hat{A}^{k}=\operatorname{softmax}\left(\frac{\hat{Q}_{k} \times \hat{K}_{k}^{T}}{\sqrt{d}}\right)$
Q和K分别是第k个视图的查询和秘钥矩阵，A可以被视为该视图的权重矩阵，一个新的multi-view图为$M=\{\hat{A^1}, .., \hat{A^t}\}$
## Aggregation
上面得到了一系列的潜在图:$G_{all}=\{G_1, ..., G_N\}$，N是图学习的论述。
每个潜在图表示（即，i=1，…，N的$H^{G_i}$）被馈送到前馈层进行降维，然后与其他潜在图表示串联。聚合模块通过线性变换汇总连接的结果，线性变换映射潜在图$G_{all}∈ R^{（d×N）×N}$到$G′∈ R{d×n}$。然后通过最大化聚合输出：$f（G′）：R^{d×n}\rightarrow R^d$获得最终的图上下文表示。此外，我们将与感兴趣的实体对相对应的节点表示添加到聚合中，以更好地进行表示学习。
# Complexity
- 图初始化： $\mathcal{O}\left(d^{2} n^{2} t\right)$, 
- 图学习： $\mathcal{O}\left(\left(d^{2}|E|+d n+d^{2} n\right) t\right)$, 
- 图细化： $\mathcal{O}\left(\left(d n(d+n)+d^{2}|E|+\right.\right.$ $\left.\left.d n+d^{2} n\right) t\right)$ 
- 聚合：$\mathcal{O}\left(d^{2} n N\right)$

n是节点数，|E|表示边数，d是隐藏层尺度，t是视图数，N是图学习轮数。
整体复杂度：$d^2n^2$
## classification
在该模块中，集成了图形学习和预训练语言模型的表示，以指导重新任务。对于预训练语言模型的表示H0，我们将h1作为序列的上下文表示，并使用均值池来提取实体信息：
$h_{e_{s}}=\frac{1}{j-i+1} \sum_{p=i}^{j} h_{p}$
$h_{e_{o}}=\frac{1}{m-k+1} \sum_{p=k}^{m} h_{p}$
其中hp是训练前语言模型的第p个token表示。我们将预训练语言模型和图形表示连接起来，以获得最终的融合关系表示，然后将其提供给softmax分类器，以输出关系上的概率分布：
$h_{r}=\left[h_{e_{s}} ; f_{e_{s}} ; h_{e_{0}} ; f_{e_{0}} ; h_{1} ; f_{\text {context }}\right]$
$y_{r}=\operatorname{softmax}\left(W_{r} h_{r}+b_{r}\right)$
$L=\sum_r(-\frac{1}{L}\sum _{i=1}^L)$
$其中f_{e_s}、f_{e_{o}}是潜在图中的结果实体表示，$
$f_{context}是通过合并整个潜在图的上下文表示。$
$y^i_r是第i类的估计概率，L是关系类型的数量$
$W_r是权重矩阵，b_r是偏差。$