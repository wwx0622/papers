# title

[graph2vec: Learning Distributed Representations of Graphs](https://arxiv.org/abs/1707.05005)
《graph2vec: 学习图的分布式表示》
代码: <https://sites.google.com/view/graph2vec>

# Abstract

许多图形分析任务（如图形分类和聚类）需要将整个图形表示为固定长度的特征向量。虽然上述方法自然不具备学习此类表示的能力，但图核仍然是获取它们的最有效方法。然而，这些图形内核使用手工制作的特性（例如，最短路径、graphlets等），因此受到泛化能力差等问题的阻碍。为了解决这个局限性，在这项工作中，我们提出了一个名为graph2vec的神经嵌入框架来学习任意大小图的数据驱动分布式表示。graph2vec的嵌入是在无监督的方式下学习的，并且不受任务限制。因此，它们可以用于任何下游任务，如图分类、聚类，甚至种子监督表示学习方法。

# Conclusion

本文提出了graph2vec，一种无监督的表示学习技术，用于学习任意大小的图的嵌入。通过我们对基准图分类数据集的大规模实验，我们证明了通过我们的方法学习的图嵌入大大优于子结构嵌入方法，并且与图核相当。
由于graph2vec是一种数据驱动的表示学习方法，当在大量图形上进行训练时，它的真正潜力就会显现出来。为此，当在两个涉及大型图形数据集的实际应用程序上进行评估时，graph2vec的性能优于最先进的图形内核，而不会影响总体性能的效率。我们在<https://sites.google.com/view/graph2vec>上提供了本研究中使用的所有代码和数据。

# Introduction

**Graph Kernels and handcrafted features**。图核是满足图形分析任务的最显著方式之一。图核通过递归地将一对图G和G'分解为原子子结构（例如，随机游走、最短路径、Graphlet等），并在子结构上定义相似性（即核）函数（例如，计算G'和G'上的公共子结构的数量），来评估它们之间的相似性（又称核值）。随后，内核方法（例如，支持向量机（SVM））可用于执行分类/聚类。然而，这些内核有两个关键限制：（1）它们中的许多没有提供显式的图形嵌入。这使得使用通用ML算法操作矢量嵌入（例如，随机森林（RFs）、神经网络等）时，无法使用图形数据。（2） 这些内核所利用的子结构（即walk、path等）是
“手工制作”，即使用特定定义明确的函数手动确定，这些函数有助于从图形中提取此类子结构。然而，当这种手工绘制的特征用于大型图形数据集时，会导致构建非常高维、稀疏和非光滑的表示，从而导致泛化较差。我们注意到，用从数据中自动学习的功能替换手工制作的功能可能有助于修复上述两个限制。

**Learning substructure embeddings**: 最近，提出了几种方法来学习图子结构的嵌入，例如节点、路径和子图。这些嵌入可以直接用于基于子结构的分析任务，例如节点分类、社区检测和链接预测。然而，这些子结构表示学习方法无法学习整个图的表示，因此不能用于图分类等任务。正如我们在x5中的实验所表明的，通过简单的扩展（如子结构嵌入上的平均或最大池）获得图嵌入会导致次优结果。

**Learning task-specific graph embeddings**: 另一方面，最近提出了一些有监督的方法（即需要图形类标签的方法）来学习整个图形嵌入，例如Patchy-san。虽然它们在监督学习任务（如图形分类）中表现出色，但它们存在两个严重的限制，降低了可用性：（1）作为基于深度神经网络的表示学习方法，它们需要大量标记数据来学习有意义的表示。显然，获取这些数据集本身就是一个挑战，因为它需要巨大的标记工作。（2） 由此学习到的表述特定于一个特定的ML任务，不能用于或转移到其他任务或问题。例如，使用Patchy-san学习的MUTAG数据集中化合物的图形嵌入专门用于预测化合物是否对细菌具有诱变作用。因此，相同的嵌入不能用于任何其他任务，例如预测化合物的性质。为了避免这些限制，类似于上述子结构表示学习方法，我们需要一种完全无监督的方法，能够以嵌入的形式简洁地捕获整个图的一般特征。据我们所知，目前还没有这样的技术。因此，在这个动机的驱动下，在这项工作中，我们朝着以无监督的方式学习任意大小图形的任务无关表示迈出了第一步。

为此，本文提出并开发了一个名为graph2vec的神经嵌入框架。受最近提出的神经文档嵌入模型的成功启发，我们将其扩展到学习图形嵌入。这些文档嵌入模型利用单词/单词序列组成文档的方式来学习其嵌入。类似地，在graph2vec中，我们建议将整个图视为文档，将图中每个节点周围的根子图视为组成文档的单词，并扩展文档嵌入神经网络以学习整个图的表示。据我们所知，graph2vec是第一种学习整个图形表示的神经嵌入方法，与图核和其他子结构嵌入方法相比，它具有以下关键优势：

1. 无监督表示学习：graph2vec以完全无监督的方式学习图形嵌入，即学习图形嵌入不需要图形的类标签。这允许我们在难以获得标记数据的大量应用程序中轻松使用graph2vec嵌入。
2. 与任务无关的嵌入：由于graph2vec在其表示学习过程中不利用任何特定于任务的信息（例如类标签），因此它提供的嵌入是通用的。这允许我们在涉及整个图形的所有分析任务中使用这些嵌入。事实上，graph2vec嵌入可以用于种子监督表示学习方法。
3. 数据驱动嵌入：与图形内核不同，graph2vec从大量图形数据中学习图形嵌入。这使得graph2vec能够绕过上述基于手工特征的嵌入方法的缺点。
4. 捕获结构等价性：与sub2vec等方法不同，sub2vec对图中的线性子结构进行采样并从中学习图嵌入，我们的框架对非线性子结构进行了采样并考虑了非线性子结构，即用于学习嵌入的根子图。考虑到这种非线性子结构，已知可以保持结构等效性1，因此这可以确保graph2vec的表示学习过程为结构相似的图生成类似的嵌入。

# 总结

该论文的工作是学习一个函数$f: G \rightarrow vector$，未涉及到节点与关系结构。
