# title
[LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models](https://arxiv.org/abs/2212.04088)

# Abstract

本研究的重点是使用大型语言模型（LLM）作为嵌入代理的规划器，该嵌入代理可以遵循自然语言指令在视觉感知环境中完成复杂任务。
现有方法的高数据成本和较差的采样效率阻碍了能够执行许多任务并能够快速学习新任务的通用代理的开发。在这项工作中，我们提出了一种新的方法LLM Planner，该方法利用大型语言模型的强大功能为具体代理进行少量射击计划。我们进一步提出了一种简单但有效的方法，通过物理基础来增强LLM，以生成和更新基于当前环境的计划。在ALFRED数据集上的实验表明，我们的方法可以实现非常有竞争力的少镜头性能：尽管使用了不到0.5%的配对训练数据，LLM Planner还是通过使用完整训练数据训练的最新基线实现了有竞争力的性能。现有方法几乎无法完成任何ta

# 1. Instruction

当代语言驱动的代理仍然需要大量的标记示例（语言指令对和黄金轨迹）来学习每项任务，这是非常昂贵的。
最近，大型语言模型（LLM）展示了非凡潜力。
但现有的工作仍然存在显著的局限性，可能会阻止更大规模的应用超出其有限的评估设置。例如，SayCan[1]是将LLM用于具体指令跟随的开创性工作之一，在有15个对象的环境中进行评估。
假设代理能够预先列举所有可接受的技能（即[动作，对象]对），因此可以使用LLM对技能进行排名。

在具有更多对象的更复杂的环境中，成本也可能迅速累积，因为代理需要调用LLM来评估每一步的每一项可接受技能；同时效率降低。最后，大多数现有工作使用LLM从语言指令生成单个静态计划，然后在整个计划上执行。然而，同一语言教学的最佳计划取决于环境；不同的环境可能需要不同的计划。缺乏一种根据环境感知动态调整LLM计划的方法。

在现有工作的基础上，我们提出了LLM-Planner，这是一种基于LLM的计划器，用于具体的指令跟随。一个重要的设计目标是能够在不同的、部分可观察的环境中处理各种任务，并能够根据环境的感知动态调整计划。

1. LLM直接生成计划
2. 根据观察到的内容动态重新规划，产生更可靠的计划

此外，我们遵循ICL范式，只使用少量配对示例。
此外，不需要更新参数，节省了开发时间。对于图1中的例子，在一集（t=0）的开头，给定一条自然语言指令，我们通过在其上下文中给LLM几个示例对（指令，HLP(高级计划)），直接提示LLM生成HLP。
我们还利用已建立的技术，如动态上下文示例检索和logit偏差，以进一步提高上下文学习性能。

虽然LLM生成的HLP乍一看已经是合理的，但它们仍然缺乏具体代理的一个基本方面——物理基础；即，生成的HLP需要基于代理所处的环境。
为了克服这个问题，我们提出了一种新的基于基础的重新规划算法，为LLM-Planner提供了物理基础。具体来说，当代理执行初始HLP时，每当它采取了太多步骤来达到当前子目标或进行了太多失败的尝试时，我们都会再次动态提示LLM生成此时已完成的部分HLP的新延续。作为基础，我们将迄今为止在环境中感知的对象列表添加到提示中，作为对当前环境的简单但有效的描述。代理用在环境中观察到的对象重新提示LLM，LLM-Planner从头开始生成一个新的HLP（因为到目前为止还没有完成子目标）。通过引入一种结合环境反馈的方法，我们的目标是在环境和LLM之间创建一个闭环，LLM可以根据环境动态调整生成的高级计划

我们在ALFRED上评估LLM-Planner，这是一个具有不同的部分可观察环境和各种任务和对象的大规模数据集。LLM仅用0.5%对象对训练数据就达到了HLSM一样的性能。

我们的工作通过利用LLM和基础的力量，为开发多功能、高效采样的具体代理打开了一扇新的大门。

# 3. Preliminaries

- ***Vision-and-Language Navigation, 视觉和语言导航***: 具体的指令跟随通常也被称为视觉和语言导航（VLN），尽管它还涉及交互动作，并且通常比典型的VLN任务具有更长的时间范围。
- ***In-Context Leanring/Prompting，上下文学习/提示***: 随着LLM的兴起，ICL引起了人们的极大关注。通过设计不同的提示，LLM可以适应不同的下游任务，并通过几个示例进行演示，而无需更新任何参数。
- ***True Few-shot Setting, 真正的少样本设置***。虽然只使用了少量的训练示例，但许多少样本研究使用了大型验证集来进行快速设计和模型选择。

# 4. LLM-Planner
在本节中，我们描述了我们的方法LLM Planner，它利用LLM（如GPT-3（TEXT-DAVINCI003））为具体代理进行基于少量镜头的高级规划。

## 4.1 Overview

要使LLM成为高级规划者，第一步是设计一个适当的提示，引导他们制定高级计划。我们将在第4.2节中讨论我们的即时设计。我们采用k-近邻（kNN）检索器来选择上下文中的示例（第4.3节）。我们还使用logit偏差来进一步将LLM的输出空间约束为允许的动作和对象集。通过以上所有设计，我们已经获得了LLM-Planner的静态版本，它已经可以生成合理的HLP。在第4.4节中，我们提出了一种新的基础重新规划算法，以增强LLM对当前环境的接地能力，从而进一步提高HLP质量。最后，我们在第4.5节中讨论了如何将LLM Planner集成到现有的具体代理中，以使其具有少量的射击计划功能。LLM Planner的概述如图2所示。

## 4.2. Prompt Design

虽然GPT-3在各种任务中被证明是一个强大的少样本学习者，但它的力量只能通过精心设计的针对所需行为的提示来释放。最终的HLP质量可能对提示中的次要设计选择敏感（例如，HLP的呈现方式，有时甚至标点符号的选择）。
因此，我们确定了提示的核心组件，并在基于留一交叉验证（LOOCV）的真实少样本设置下系统地比较了不同的设计选择。第5.5节和第5.6节讨论了一些关键设计选择的评估。

提示以任务的直观说明和允许的高级操作列表开始。然后是kNN检索器选择的上下文中的示例（第4.3节）。当我们只向GPT-3提供高级目标指令时，我们使用“Task description: [high-level goal instruction]”的格式。当我们包括分步指令时，在目标指令后面包括另一行“Step-by-step instructions: [step-by-step instructions]”。对于基于动态的重新规划（第4.4节），我们在任务描述之后添加已完成的子目标和迄今为止在环境中观察到的对象列表。最后，我们以相同的格式附加测试示例，并以“Next plan:”结尾。
![Alt text](../../image/大模型/LLM-Planner/image%2001.png)

## 4.3. In-context Example Retrieval

上下文中的示例是LLM任务特定信息的重要来源。不同的示例可以为当前任务提供不同的信息。
直观地说，如果当前任务是“煮土豆”，那么演示“煮鸡蛋”的HLP的上下文示例可能比演示如何“清洁盘子”的示例更具信息性。具体而言，我们使用冻结的BERT-base模型来评估每个训练示例和当前测试示例之间的成对相似性。两个例子的相似性是基于其相应指令的BERT嵌入之间的欧几里得距离来定义的。对于每个测试示例，我们从我们拥有的一小组配对训练示例中检索K个最相似的示例，其中K是我们在真正的少样本设置下调整的超参数（第5.6节）。

## 4.4. Grounded Re-planning

使用LLM Planner作为静态高级规划器，只在任务开始时预测HLP，已经显示出良好的数据效率和准确性。然而，如前所述，这种静态规划缺乏物理环境的基础，可能导致不正确的对象和无法实现的计划。当此类问题发生时，代理无法完成HLP中指定的当前子目标，这将导致两种可能的情况之一：1）无法执行一个动作（例如撞到墙上或无法与对象交互），或者2）花费了很长时间，仍然没有完成当前子目标（例如无休止地漫游）。直观地说，了解当前环境中的对象对于解决这两个问题非常有帮助。例如，在知道有冰箱的情况下，LLM可能会产生一个HLP，引导代理去冰箱，并试图在里面找到土豆，因为它可能已经学会了食物需要存储的常识。

为此，我们提出了一种简单但有效的方法，通过将观察到的对象列表从环境中注入到提示中，来增强具有物理基础的LLM。我们还为这些观察到的对象添加了logit偏差，这样LLM Planner就可以在这些对象与任务相关的情况下，优先使用这些对象制定计划。

在此基础上，我们提出了一种基于基础的重新规划算法（算法1），以在完成任务的过程中动态更新HLP。在我们的算法中，在以下两种情况中的任何一种情况下都会触发重新规划：1）代理无法执行动作，或者2）在固定数量的时间步长之后。LLM Planner将根据观察到的对象生成已经完成的部分HLP的新延续，代理将继续执行新计划，这可能有助于它摆脱困境。
![Alt text](../../image/大模型/LLM-Planner/image%2002.png)

## 4.5. Integration with Existing VLN models

我们现在讨论如何将LLM Planner与现有模型集成，以增强它们的少镜头规划能力。LLM Planner为集成提供了一个相当通用和灵活的界面。如算法1所示，它只需要包含的代理提供一个对象列表，并具有一个低级计划器，可以将预测的HLP转化为低级动作。它对代理人的内部工作没有任何假设。为了评估LLM Planner的端到端任务完成性能，我们将其与满足这种接口的强基线方法HLSM[3]集成。
