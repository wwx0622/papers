# title
[ZeRO](https://arxiv.org/pdf/1910.02054.pdf)
同时介绍了deepspeed框架

# 摘要

大型深度学习模型提供了显著的准确性提高，但训练数十亿到数万亿的参数是具有挑战性的。
现有的解决方案，如数据和模型并行性，在获得计算、通信和开发效率的同时，显示出将这些模型放入有限的设备内存的基本局限性。
我们开发了一种新的解决方案，零冗余优化器（Zero Redundancy Optimizer, ZeRO），用于优化内存，极大地提高了训练速度，同时增加了可以有效训练的模型大小。ZeRO消除了数据和模型并行训练中的内存冗余，同时保持了低通信量和高计算粒度，使我们能够以持续高效的方式根据设备数量按比例缩放模型大小。

# 训练流程

初始状态
假设有Nd个gpu，则每个gpu（gpu_n）保存总参数的1/Nd;并且保存这些参数对应的梯度、优化器状态(P_n,G_n,O_n)；参数可以按层划分；每个gpu_n同时还负责分配到自己身上的数据data_n（数据并行）；

正向计算第一层时，gpu_n将自己负责的参数(P_n)广播给其它所有的gpu；后面的模型层以此类推；最后每个gpu_n获得自己对应数据data_n的loss_n；
进行反向计算，此时需要gpu_n将自己负责的参数(P_n)广播给其它所有的gpu，最后计算得到对应于数据data_n的梯度；
将第二步的梯度聚合到对应的gpu_n上，每个gpu负责更新自己的P_n,G_n,O_n；
进行下一次迭代
